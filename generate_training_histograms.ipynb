{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cbe8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.5 (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow==2.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install scipy\n",
    "# !pip install sklearn\n",
    "!pip install tensorflow==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e172ff08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MiniBatchKMeans\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd041495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Bag of Features Model\n",
    "\n",
    "def orb_features(images):\n",
    "  orb_descriptors_class_by_class={}\n",
    "  orb_descriptors_list=[]\n",
    "  orb=cv2.xfeatures2d.ORB_create()\n",
    "  for key,value in images.items():\n",
    "    print(key, \"Started\")\n",
    "    features=[]\n",
    "    for img in value:\n",
    "      kp,desc=orb.detectAndCompute(img,None)\n",
    "      orb_descriptors_list.extend(desc)\n",
    "      features.append(desc)\n",
    "    orb_descriptors_class_by_class[key]=features\n",
    "    print(key,\" Completed!\")\n",
    "  return [orb_descriptors_list,orb_descriptors_class_by_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db908b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a visual dictionary using only the train dataset \n",
    "# K-means clustering alogo takes only 2 parameters which are number of clusters (k) and descrpitors list\n",
    "# It reurn an array which holds central points\n",
    "\n",
    "def minibatchkmeans(k, descriptors_list):\n",
    "  kmeans=MiniBatchKMeans(n_clusters=k)\n",
    "  print(\"MiniBatchKMeans Initialized!\")\n",
    "  kmeans.fit(descriptors_list)\n",
    "  print(\"Clusters Created!\")\n",
    "  visual_words=kmeans.cluster_centers_\n",
    "  return visual_words, kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cfbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train images into dictionaries which holds all images category by category\n",
    "\n",
    "def load_images_by_category(folder):\n",
    "  images={}\n",
    "  for label in os.listdir(folder):\n",
    "    print(label,\" started\")\n",
    "    category=[]\n",
    "    path=folder+'/'+label\n",
    "    for image in os.listdir(path):\n",
    "      img=cv2.imread(path+'/'+image)\n",
    "      #new_img=cv2.resize(img,(128,128))\n",
    "      if img is not None:\n",
    "        category.append(img)\n",
    "    images[label]=category\n",
    "    print(label, \"ended\")\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating histograms for train images\n",
    "\n",
    "# Function takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
    "# And the second parameter is the clustered model\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "\n",
    "def create_histogram(all_descs,kmeans):\n",
    "  features_dict={}\n",
    "  for key,value in all_descs.items():\n",
    "    print(key,\" Started!\")\n",
    "    category=[]\n",
    "    for desc in value:\n",
    "      raw_words=kmeans.predict(desc)\n",
    "      hist = np.array(np.bincount(raw_words,minlength=n_classes*clustering_factor))\n",
    "      category.append(hist)\n",
    "    features_dict[key]=category\n",
    "    print(key,\" Completed!\")\n",
    "  return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder='C:/Users/Sandeep Roy/Desktop/data2/data/Train-Test/Train'\n",
    "\n",
    "# Load train images\n",
    "train_images=load_images_by_category(train_folder)\n",
    "#print(len(train_images))\n",
    "\n",
    "#print(len(train_images['a'][0][0]))\n",
    "\n",
    "#Extracting orb features from each image stored in train_images list\n",
    "\n",
    "orbs=orb_features(train_images)\n",
    "all_train_descriptors=orbs[0]\n",
    "train_descriptors_by_class=orbs[1]\n",
    "\n",
    "#print(len(orbs[0]))\n",
    "#print(len(orbs[1]['0'][1]))\n",
    "\n",
    "# Calling MiniBatchkmeans function and getting central points\n",
    "visual_words,kmeans=minibatchkmeans(n_classes*clustering_factor,all_train_descriptors)\n",
    "\n",
    "\n",
    "# Calling create_histogram and getting histogram for each image\n",
    "bows_train=create_histogram(train_descriptors_by_class,kmeans)\n",
    "\n",
    "#print((bows_train['a'][0][1]))\n",
    "\n",
    "# Saving .csv file\n",
    "import csv\n",
    "loc='cnn files/train.csv'\n",
    "with open(loc,'w',newline='') as file:\n",
    "  writer=csv.writer(file)\n",
    "  header=[]\n",
    "  for i in range (1,n_classes*clustering_factor):\n",
    "    header.append(str('pixel')+str(i))\n",
    "  header.append('Label')\n",
    "  writer.writerow(header)\n",
    "  count=0\n",
    "  for label in bows_train:\n",
    "     # print(len(bows_train[label]))\n",
    "    for i in range(len(bows_train[label])):\n",
    "      list=[]\n",
    "      for j in range(150):\n",
    "        list.append(bows_train[label][i][j])\n",
    "      list.append(label)\n",
    "      writer.writerow(list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
