{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b67943e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install tensorflow==1.15.2\n",
    "# !pip install scipy\n",
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "309a11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0e7c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detect hardware\n",
    "# try:\n",
    "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "# except ValueError:\n",
    "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413eea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Bag of Features Model\n",
    "n_classes=36\n",
    "clustering_factor=6\n",
    "\n",
    "def orb_features(images):\n",
    "  orb_descriptors_class_by_class={}\n",
    "  orb_descriptors_list=[]\n",
    "  orb=cv2.ORB_create()\n",
    "  for key,value in images.items():\n",
    "    print(key, \"Started\")\n",
    "    features=[]\n",
    "    for img in value:\n",
    "      kp,desc=orb.detectAndCompute(img,None)\n",
    "      orb_descriptors_list.extend(desc)\n",
    "      features.append(desc)\n",
    "    orb_descriptors_class_by_class[key]=features\n",
    "    print(key,\" Completed!\")\n",
    "  return [orb_descriptors_list,orb_descriptors_class_by_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "963ff88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a visual dictionary using only the train dataset \n",
    "# K-means clustering alogo takes only 2 parameters which are number of clusters (k) and descrpitors list\n",
    "# It reurn an array which holds central points\n",
    "\n",
    "def minibatchkmeans(k, descriptors_list):\n",
    "  kmeans=MiniBatchKMeans(n_clusters=k)\n",
    "  print(\"MiniBatchKMeans Initialized!\")\n",
    "  kmeans.fit(descriptors_list)\n",
    "  print(\"Clusters Created!\")\n",
    "  visual_words=kmeans.cluster_centers_\n",
    "  return visual_words, kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "429cfcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train images into dictionaries which holds all images category by category\n",
    "\n",
    "def load_images_by_category(folder):\n",
    "  images={}\n",
    "  for label in os.listdir(folder):\n",
    "    print(label,\" started\")\n",
    "    category=[]\n",
    "    path=folder+'/'+label\n",
    "    for image in os.listdir(path):\n",
    "      img=cv2.imread(path+'/'+image)\n",
    "      #new_img=cv2.resize(img,(128,128))\n",
    "      if img is not None:\n",
    "        category.append(img)\n",
    "    images[label]=category\n",
    "    print(label, \"ended\")\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02059feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating histograms for train images\n",
    "\n",
    "# Function takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
    "# And the second parameter is the clustered model\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "\n",
    "def create_histogram(all_descs,kmeans):\n",
    "  features_dict={}\n",
    "  for key,value in all_descs.items():\n",
    "    print(key,\" Started!\")\n",
    "    category=[]\n",
    "    for desc in value:\n",
    "      raw_words=kmeans.predict(desc)\n",
    "      hist = np.array(np.bincount(raw_words,minlength=n_classes*clustering_factor))\n",
    "      category.append(hist)\n",
    "    features_dict[key]=category\n",
    "    print(key,\" Completed!\")\n",
    "  return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37e58e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  started\n",
      "1 ended\n",
      "2  started\n",
      "2 ended\n",
      "3  started\n",
      "3 ended\n",
      "4  started\n",
      "4 ended\n",
      "5  started\n",
      "5 ended\n",
      "6  started\n",
      "6 ended\n",
      "7  started\n",
      "7 ended\n",
      "8  started\n",
      "8 ended\n",
      "9  started\n",
      "9 ended\n",
      "a  started\n",
      "a ended\n",
      "b  started\n",
      "b ended\n",
      "c  started\n",
      "c ended\n",
      "d  started\n",
      "d ended\n",
      "e  started\n",
      "e ended\n",
      "f  started\n",
      "f ended\n",
      "g  started\n",
      "g ended\n",
      "h  started\n",
      "h ended\n",
      "i  started\n",
      "i ended\n",
      "j  started\n",
      "j ended\n",
      "k  started\n",
      "k ended\n",
      "l  started\n",
      "l ended\n",
      "m  started\n",
      "m ended\n",
      "n  started\n",
      "n ended\n",
      "o  started\n",
      "o ended\n",
      "p  started\n",
      "p ended\n",
      "q  started\n",
      "q ended\n",
      "r  started\n",
      "r ended\n",
      "s  started\n",
      "s ended\n",
      "t  started\n",
      "t ended\n",
      "u  started\n",
      "u ended\n",
      "v  started\n",
      "v ended\n",
      "w  started\n",
      "w ended\n",
      "x  started\n",
      "x ended\n",
      "y  started\n",
      "y ended\n",
      "z  started\n",
      "z ended\n",
      "1 Started\n",
      "1  Completed!\n",
      "2 Started\n",
      "2  Completed!\n",
      "3 Started\n",
      "3  Completed!\n",
      "4 Started\n",
      "4  Completed!\n",
      "5 Started\n",
      "5  Completed!\n",
      "6 Started\n",
      "6  Completed!\n",
      "7 Started\n",
      "7  Completed!\n",
      "8 Started\n",
      "8  Completed!\n",
      "9 Started\n",
      "9  Completed!\n",
      "a Started\n",
      "a  Completed!\n",
      "b Started\n",
      "b  Completed!\n",
      "c Started\n",
      "c  Completed!\n",
      "d Started\n",
      "d  Completed!\n",
      "e Started\n",
      "e  Completed!\n",
      "f Started\n",
      "f  Completed!\n",
      "g Started\n",
      "g  Completed!\n",
      "h Started\n",
      "h  Completed!\n",
      "i Started\n",
      "i  Completed!\n",
      "j Started\n",
      "j  Completed!\n",
      "k Started\n",
      "k  Completed!\n",
      "l Started\n",
      "l  Completed!\n",
      "m Started\n",
      "m  Completed!\n",
      "n Started\n",
      "n  Completed!\n",
      "o Started\n",
      "o  Completed!\n",
      "p Started\n",
      "p  Completed!\n",
      "q Started\n",
      "q  Completed!\n",
      "r Started\n",
      "r  Completed!\n",
      "s Started\n",
      "s  Completed!\n",
      "t Started\n",
      "t  Completed!\n",
      "u Started\n",
      "u  Completed!\n",
      "v Started\n",
      "v  Completed!\n",
      "w Started\n",
      "w  Completed!\n",
      "x Started\n",
      "x  Completed!\n",
      "y Started\n",
      "y  Completed!\n",
      "z Started\n",
      "z  Completed!\n",
      "MiniBatchKMeans Initialized!\n",
      "Clusters Created!\n",
      "1  Started!\n",
      "1  Completed!\n",
      "2  Started!\n",
      "2  Completed!\n",
      "3  Started!\n",
      "3  Completed!\n",
      "4  Started!\n",
      "4  Completed!\n",
      "5  Started!\n",
      "5  Completed!\n",
      "6  Started!\n",
      "6  Completed!\n",
      "7  Started!\n",
      "7  Completed!\n",
      "8  Started!\n",
      "8  Completed!\n",
      "9  Started!\n",
      "9  Completed!\n",
      "a  Started!\n",
      "a  Completed!\n",
      "b  Started!\n",
      "b  Completed!\n",
      "c  Started!\n",
      "c  Completed!\n",
      "d  Started!\n",
      "d  Completed!\n",
      "e  Started!\n",
      "e  Completed!\n",
      "f  Started!\n",
      "f  Completed!\n",
      "g  Started!\n",
      "g  Completed!\n",
      "h  Started!\n",
      "h  Completed!\n",
      "i  Started!\n",
      "i  Completed!\n",
      "j  Started!\n",
      "j  Completed!\n",
      "k  Started!\n",
      "k  Completed!\n",
      "l  Started!\n",
      "l  Completed!\n",
      "m  Started!\n",
      "m  Completed!\n",
      "n  Started!\n",
      "n  Completed!\n",
      "o  Started!\n",
      "o  Completed!\n",
      "p  Started!\n",
      "p  Completed!\n",
      "q  Started!\n",
      "q  Completed!\n",
      "r  Started!\n",
      "r  Completed!\n",
      "s  Started!\n",
      "s  Completed!\n",
      "t  Started!\n",
      "t  Completed!\n",
      "u  Started!\n",
      "u  Completed!\n",
      "v  Started!\n",
      "v  Completed!\n",
      "w  Started!\n",
      "w  Completed!\n",
      "x  Started!\n",
      "x  Completed!\n",
      "y  Started!\n",
      "y  Completed!\n",
      "z  Started!\n",
      "z  Completed!\n"
     ]
    }
   ],
   "source": [
    "train_folder='C:/Users/Sandeep Roy/Desktop/data2/data/Train'\n",
    "\n",
    "# Load train images\n",
    "train_images=load_images_by_category(train_folder)\n",
    "#print(len(train_images))\n",
    "\n",
    "#print(len(train_images['a'][0][0]))\n",
    "\n",
    "#Extracting orb features from each image stored in train_images list\n",
    "\n",
    "orbs=orb_features(train_images)\n",
    "all_train_descriptors=orbs[0]\n",
    "train_descriptors_by_class=orbs[1]\n",
    "\n",
    "#print(len(orbs[0]))\n",
    "#print(len(orbs[1]['0'][1]))\n",
    "\n",
    "# Calling MiniBatchkmeans function and getting central points\n",
    "visual_words,kmeans=minibatchkmeans(n_classes*clustering_factor,all_train_descriptors)\n",
    "\n",
    "\n",
    "# Calling create_histogram and getting histogram for each image\n",
    "bows_train=create_histogram(train_descriptors_by_class,kmeans)\n",
    "\n",
    "#print((bows_train['a'][0][1]))\n",
    "\n",
    "# Saving .csv file\n",
    "import csv\n",
    "loc='C:/Users/Sandeep Roy/Desktop/data2/data/train.csv'\n",
    "with open(loc,'w',newline='') as file:\n",
    "  writer=csv.writer(file)\n",
    "  header=[]\n",
    "  for i in range (1,n_classes*clustering_factor):\n",
    "    header.append(str('pixel')+str(i))\n",
    "  header.append('Label')\n",
    "  writer.writerow(header)\n",
    "  count=0\n",
    "  for label in bows_train:\n",
    "     # print(len(bows_train[label]))\n",
    "    for i in range(len(bows_train[label])):\n",
    "      list=[]\n",
    "      for j in range(150):\n",
    "        list.append(bows_train[label][i][j])\n",
    "      list.append(label)\n",
    "      writer.writerow(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3848fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Kmeans model\n",
    "with open('kmeans_model.pkl','wb') as f:\n",
    "    pickle.dump(kmeans, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef5e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
